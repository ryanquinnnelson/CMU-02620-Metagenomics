{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "common-equivalent",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "emerging-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.metagenomics import sampling2, encoding2\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "from Bio.Seq import Seq\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import csv\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-international",
   "metadata": {},
   "source": [
    "### Ideas for model improvement\n",
    "- consider setting class weights to reflect unequal distribution of data\n",
    "- try different loss functions\n",
    "- try one-vs-all approach\n",
    "- encode sequences differently depending on whether sequence is a promoter or gene vs CpG islands, etc. Search for known motifs rather than blind k-mer groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-bible",
   "metadata": {},
   "source": [
    "### Run Grid Search 1 - Multiclass Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lucky-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_results_to_file(filename, fields=None, rows=None):\n",
    "    \n",
    "    with open(filename, 'a') as f:\n",
    "\n",
    "        write = csv.writer(f)\n",
    "\n",
    "        if fields:\n",
    "            write.writerow(fields)\n",
    "\n",
    "        if rows:\n",
    "            write.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "specific-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf_classification(X_train, X_test, y_train,y_test, max_depth, n_estimators, seed):\n",
    "   \n",
    "    rf = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, random_state=seed)\n",
    "    rf.fit(X_train,y_train)\n",
    "    score = rf.score(X_test, y_test)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flexible-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fragments(seq_file, taxid_file, output_dir, sample_length, coverage, seed):\n",
    "    # delete output directory if it previously exists\n",
    "    try:\n",
    "        shutil.rmtree(output_dir)\n",
    "    except FileNotFoundError:\n",
    "        print('Existing directory was not found.')\n",
    "\n",
    "    # build fragments\n",
    "    sampling2.generate_fragment_data(seq_file, taxid_file, output_dir, sample_length, coverage, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "floral-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fragments(output_dir, pattern, k, seed):\n",
    "    \n",
    "    # encode data\n",
    "    fragments = sampling2.read_fragments(output_dir, pattern)\n",
    "    X_enc, y = encoding2.encode_fragment_dataset(fragments,k)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    # split data into test and training\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_enc, y_enc, test_size=0.33, random_state=seed)\n",
    "    \n",
    "    print(X_enc.shape)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advanced-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_number_combinations(list_sample_length,list_coverage,list_k,list_max_depth,list_n_estimators):\n",
    "    n = len(list_sample_length) * len(list_coverage) * len(list_k) *len(list_max_depth) * len(list_n_estimators)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "solar-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_multiclass_rf(seq_file, \n",
    "                              taxid_file, \n",
    "                              output_dir, \n",
    "                              pattern, \n",
    "                              list_sample_length, \n",
    "                              list_coverage, \n",
    "                              list_k,\n",
    "                              list_max_depth, \n",
    "                              list_n_estimators, \n",
    "                              seed,\n",
    "                              grid_search_file,\n",
    "                              fields,\n",
    "                              experiment):\n",
    "    \n",
    "    # set up grid search results file\n",
    "    append_results_to_file(grid_search_file, fields)\n",
    "    \n",
    "    # calculate number of combinations\n",
    "    n_combinations = calc_number_combinations(list_sample_length,list_coverage,list_k,list_max_depth,list_n_estimators)\n",
    "    \n",
    "    # process combinations\n",
    "    count = 0\n",
    "    for sample_length in list_sample_length:\n",
    "        for coverage in list_coverage:\n",
    "            \n",
    "            # fragment combination\n",
    "            build_fragments(seq_file, taxid_file, output_dir, sample_length, coverage, seed)\n",
    "            for k in list_k:\n",
    "                \n",
    "                # kmer combination\n",
    "                X_train, X_test, y_train, y_test = encode_fragments(output_dir, pattern,k,seed)\n",
    "                for max_depth in list_max_depth:\n",
    "                    for n_estimators in list_n_estimators:\n",
    "                        \n",
    "                        # random forest combination\n",
    "                        score = run_rf_classification(X_train, X_test, y_train,y_test, max_depth, n_estimators, seed)\n",
    "                        count += 1\n",
    "                        \n",
    "                        # output results to file\n",
    "                        row = [experiment, 'multiclass', 'Random Forest', sample_length, coverage, k, max_depth, n_estimators, score]\n",
    "                        append_results_to_file(grid_search_file, row)\n",
    "                        \n",
    "                print('Percent complete: {}'.format(count / n_combinations * 100)) # display progress\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acting-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hyperparameter_relationship(filename):\n",
    "    \"\"\"\n",
    "    Runs logistic regression over hyperparameters to find the regression coefficients.\n",
    "    This should give some indicator of how hyperparameters are affecting the score.\n",
    "    \"\"\"\n",
    "    # read in grid search results\n",
    "    df = pd.read_csv(filename)\n",
    "    X = df.drop(['experiment','score', 'category','classifier'],axis=1)\n",
    "    y = df['score']\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X,y)\n",
    "    return lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-miami",
   "metadata": {},
   "source": [
    "### Search 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "controlling-daisy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# fields = ['category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100, 200, 400]\n",
    "# list_coverage = [0.1, 1, 2, 10]\n",
    "# list_k = [i for i in range(1,10,2)]\n",
    "# list_max_depth = [i for i in range(2,20,4)]\n",
    "# list_n_estimators = [i for i in range(20,200,40)]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "running-torture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.44909382e-04,  1.67645287e-02, -9.17412031e-03,  1.18482770e-03,\n",
       "       -1.44167915e-05])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_file = 'data/gridsearch/rf-multi.2021.03.28.18.07.15.csv'\n",
    "calc_hyperparameter_relationship(gridsearch_file)\n",
    "# array([-1.44909382e-04,  1.67645287e-02, -9.17412031e-03,  1.18482770e-03, -1.44167915e-05])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-dragon",
   "metadata": {},
   "source": [
    "### Search 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "descending-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# 3h 37min 3s\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# fields = ['category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [200, 400]\n",
    "# list_coverage = [1,10,100,200]\n",
    "# list_k = [i for i in range(1,20,2)]\n",
    "# list_max_depth = [i for i in range(6,20,2)]\n",
    "# list_n_estimators = [i for i in range(50,501,50)]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "naughty-value",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79147764e-04,  8.02651943e-04, -1.15739138e-02,  2.46285124e-03,\n",
       "        4.98644275e-06])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_file = 'data/gridsearch/rf-multi.2021.03.28.18.31.24.csv'\n",
    "calc_hyperparameter_relationship(gridsearch_file)\n",
    "# array([-1.79147764e-04,  8.02651943e-04, -1.15739138e-02,  2.46285125e-03, 4.98644276e-06])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-opportunity",
   "metadata": {},
   "source": [
    "### Search 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alive-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "## 2h\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.3'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100, 200, 400]\n",
    "# list_coverage = [0.1,1,10,100,200]\n",
    "# list_k = [1,2,4,8]\n",
    "# list_max_depth = [i for i in range(20,51,10)]\n",
    "# list_n_estimators = [50,100,200,400,800]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-conjunction",
   "metadata": {},
   "source": [
    "### Search 1.4\n",
    "Stopped short after realizing I didn't need to try as small intervals of max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "weighted-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.4'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [200]\n",
    "# list_k = [1]\n",
    "# list_max_depth = [50]\n",
    "# list_n_estimators = [50,100,200,400,800,1600,3200]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-pendant",
   "metadata": {},
   "source": [
    "### Search 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "chinese-travel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16282, 400)\n",
      "Percent complete: 8.333333333333332\n",
      "(16282, 800)\n",
      "Percent complete: 16.666666666666664\n",
      "(16282, 6400)\n",
      "Percent complete: 25.0\n",
      "(16282, 43939)\n",
      "Percent complete: 33.33333333333333\n",
      "(8141, 800)\n",
      "Percent complete: 41.66666666666667\n",
      "(8141, 1600)\n",
      "Percent complete: 50.0\n",
      "(8141, 12799)\n",
      "Percent complete: 58.333333333333336\n",
      "(8141, 77930)\n",
      "Percent complete: 66.66666666666666\n",
      "(4071, 1600)\n",
      "Percent complete: 75.0\n",
      "(4071, 3200)\n",
      "Percent complete: 83.33333333333334\n",
      "(4071, 25514)\n",
      "Percent complete: 91.66666666666666\n",
      "(4071, 117598)\n",
      "Percent complete: 100.0\n",
      "CPU times: user 5h 5min, sys: 1min 46s, total: 5h 6min 46s\n",
      "Wall time: 5h 8min 50s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.5'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100, 200, 400]\n",
    "# list_coverage = [200]\n",
    "# list_k = [1,2,4,6]\n",
    "# list_max_depth = [50, 100, 200]\n",
    "# list_n_estimators = [50,100,200,400,800,1600,3200]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
