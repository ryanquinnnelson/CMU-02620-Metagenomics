{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unexpected-fight",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "thick-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.metagenomics import sampling2, encoding2\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "from Bio.Seq import Seq\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import csv\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-vintage",
   "metadata": {},
   "source": [
    "### Ideas for model improvement\n",
    "- consider setting class weights to reflect unequal distribution of data\n",
    "- try one-vs-all approach\n",
    "- encode sequences differently depending on whether sequence is a promoter or gene vs CpG islands, etc. Search for known motifs rather than blind k-mer groups.\n",
    "- use PCA to reduce dimensions first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-jerusalem",
   "metadata": {},
   "source": [
    "# Recall score\n",
    "From the paper: \"Performance is measured in terms of species-level recall. We first compute the prediction recall within each species, i.e. the proportion of fragments originating from this species that are correctly classified and consider the average recall observed across species.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "subjective-boundary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 1, 2, 0, 1, 2]\n",
    "y_pred = [0, 2, 1, 0, 1, 1]\n",
    "\n",
    "recall_score(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-bangkok",
   "metadata": {},
   "source": [
    "# Grid Search 1 - 2000 size dataset (4 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-macintosh",
   "metadata": {},
   "source": [
    "### Run Grid Search 1 - Multiclass Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "related-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_results_to_file(filename, fields=None, rows=None):\n",
    "    \n",
    "    with open(filename, 'a') as f:\n",
    "\n",
    "        write = csv.writer(f)\n",
    "\n",
    "        if fields:\n",
    "            write.writerow(fields)\n",
    "\n",
    "        if rows:\n",
    "            write.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "environmental-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf_classification(X_train, X_test, y_train,y_test, max_depth, n_estimators, seed):\n",
    "    \"\"\"\n",
    "    Score is subset accuracy.\n",
    "    \"\"\"\n",
    "   \n",
    "    rf = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, random_state=seed)\n",
    "    rf.fit(X_train,y_train)\n",
    "    score = rf.score(X_test, y_test)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "progressive-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf_classification_recall(X_train, X_test, y_train,y_test, max_depth, n_estimators, seed):\n",
    "    \"\"\"\n",
    "    Score is species level recall.\n",
    "    \"\"\"\n",
    "   \n",
    "    rf = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, random_state=seed)\n",
    "    rf.fit(X_train,y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred, average='weighted')\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "stone-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fragments(seq_file, taxid_file, output_dir, sample_length, coverage, seed):\n",
    "    # delete output directory if it previously exists\n",
    "    try:\n",
    "        shutil.rmtree(output_dir)\n",
    "    except FileNotFoundError:\n",
    "        print('Existing directory was not found. Process will generate a directory.')\n",
    "\n",
    "    # build fragments\n",
    "    sampling2.generate_fragment_data(seq_file, taxid_file, output_dir, sample_length, coverage, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "short-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fragments(output_dir, pattern, k, seed):\n",
    "    \n",
    "    # encode data\n",
    "    fragments = sampling2.read_fragments(output_dir, pattern)\n",
    "    X_enc, y = encoding2.encode_fragment_dataset(fragments,k)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    # split data into test and training\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_enc, y_enc, test_size=0.33, random_state=seed)\n",
    "    \n",
    "    print(X_enc.shape)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "temporal-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_number_combinations(list_sample_length,list_coverage,list_k,list_max_depth,list_n_estimators):\n",
    "    n = len(list_sample_length) * len(list_coverage) * len(list_k) *len(list_max_depth) * len(list_n_estimators)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "honest-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_multiclass_rf(seq_file, \n",
    "                              taxid_file, \n",
    "                              output_dir, \n",
    "                              pattern, \n",
    "                              list_sample_length, \n",
    "                              list_coverage, \n",
    "                              list_k,\n",
    "                              list_max_depth, \n",
    "                              list_n_estimators, \n",
    "                              seed,\n",
    "                              grid_search_file,\n",
    "                              fields,\n",
    "                              experiment,\n",
    "                             score_type):\n",
    "    \n",
    "    # set up grid search results file\n",
    "    append_results_to_file(grid_search_file, fields)\n",
    "    \n",
    "    # calculate number of combinations\n",
    "    n_combinations = calc_number_combinations(list_sample_length,list_coverage,list_k,list_max_depth,list_n_estimators)\n",
    "    \n",
    "    # process combinations\n",
    "    count = 0\n",
    "    for sample_length in list_sample_length:\n",
    "        for coverage in list_coverage:\n",
    "            \n",
    "            # fragment combination\n",
    "            build_fragments(seq_file, taxid_file, output_dir, sample_length, coverage, seed)\n",
    "            for k in list_k:\n",
    "                \n",
    "                # kmer combination\n",
    "                X_train, X_test, y_train, y_test = encode_fragments(output_dir, pattern,k,seed)\n",
    "                for max_depth in list_max_depth:\n",
    "                    for n_estimators in list_n_estimators:\n",
    "                        \n",
    "                        # random forest combination\n",
    "                        score = run_rf_classification_recall(X_train, X_test, y_train,y_test, max_depth, n_estimators, seed)\n",
    "                        count += 1\n",
    "                        \n",
    "                        # output results to file\n",
    "                        row = [experiment, 'multiclass', 'Random Forest', X_train.shape, sample_length, coverage, k, max_depth, n_estimators, score, score_type]\n",
    "                        append_results_to_file(grid_search_file, row)\n",
    "                        \n",
    "                print('Percent complete: {}'.format(count / n_combinations * 100)) # display progress\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "sapphire-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hyperparameter_relationship(filename):\n",
    "    \"\"\"\n",
    "    Runs logistic regression over hyperparameters to find the regression coefficients.\n",
    "    This should give some indicator of how hyperparameters are affecting the score.\n",
    "    \"\"\"\n",
    "    # read in grid search results\n",
    "    df = pd.read_csv(filename)\n",
    "    X = df.drop(['experiment','score', 'category','classifier'],axis=1)\n",
    "    y = df['score']\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X,y)\n",
    "    return lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "brief-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line(sample_length, coverage, df):\n",
    "    data = df[(df['sample_length'] == sample_length) & (df['coverage']==coverage)].drop(['sample_length', 'coverage'],axis=1)\n",
    "    return data['k'].tolist(), data['score'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-passion",
   "metadata": {},
   "source": [
    "### Search 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "environmental-flavor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# fields = ['category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100, 200, 400]\n",
    "# list_coverage = [0.1, 1, 2, 10]\n",
    "# list_k = [i for i in range(1,10,2)]\n",
    "# list_max_depth = [i for i in range(2,20,4)]\n",
    "# list_n_estimators = [i for i in range(20,200,40)]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "selected-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch_file = 'data/gridsearch/rf-multi.2021.03.28.18.07.15.csv'\n",
    "# calc_hyperparameter_relationship(gridsearch_file)\n",
    "# # array([-1.44909382e-04,  1.67645287e-02, -9.17412031e-03,  1.18482770e-03, -1.44167915e-05])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-notice",
   "metadata": {},
   "source": [
    "### Search 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "distinct-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# 3h 37min 3s\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.' + datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') + '.csv'\n",
    "# fields = ['category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [200, 400]\n",
    "# list_coverage = [1,10,100,200]\n",
    "# list_k = [i for i in range(1,20,2)]\n",
    "# list_max_depth = [i for i in range(6,20,2)]\n",
    "# list_n_estimators = [i for i in range(50,501,50)]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "prompt-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch_file = 'data/gridsearch/rf-multi.2021.03.28.18.31.24.csv'\n",
    "# calc_hyperparameter_relationship(gridsearch_file)\n",
    "# # array([-1.79147764e-04,  8.02651943e-04, -1.15739138e-02,  2.46285125e-03, 4.98644276e-06])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-rhythm",
   "metadata": {},
   "source": [
    "### Search 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "numeric-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "## 2h\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.3'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100, 200, 400]\n",
    "# list_coverage = [0.1,1,10,100,200]\n",
    "# list_k = [1,2,4,8]\n",
    "# list_max_depth = [i for i in range(20,51,10)]\n",
    "# list_n_estimators = [50,100,200,400,800]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-bracelet",
   "metadata": {},
   "source": [
    "### Search 1.4\n",
    "Stopped short after realizing I didn't need to try as small intervals of max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "progressive-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.4'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [200]\n",
    "# list_k = [1]\n",
    "# list_max_depth = [50]\n",
    "# list_n_estimators = [50,100,200,400,800,1600,3200]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-celtic",
   "metadata": {},
   "source": [
    "### Search 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "contemporary-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "## 5.5 h\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.5'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100, 200, 400]\n",
    "# list_coverage = [200]\n",
    "# list_k = [1,2,4,6]\n",
    "# list_max_depth = [50, 100, 200]\n",
    "# list_n_estimators = [50,100,200,400,800,1600,3200]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-rebel",
   "metadata": {},
   "source": [
    "### Search 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "governing-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #2.25 h\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.6'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [200]\n",
    "# list_k = [1,2,3]\n",
    "# list_max_depth = [55, 65, 75, 85, 95]\n",
    "# list_n_estimators = [400,500,600,700,800]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "respective-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch_file = 'data/gridsearch/rf-multi-all.csv'\n",
    "# calc_hyperparameter_relationship(gridsearch_file)\n",
    "# # array([-1.95530967e-04,  1.27461350e-03, -1.10693995e-02,  1.45827089e-03, 4.77729253e-05])\n",
    "# # x1000 =\n",
    "# # -0.19  sample length\n",
    "# #  1.27  coverage\n",
    "# # -10    k\n",
    "# #  1.45  max_depth\n",
    "# #  0.047 n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-abraham",
   "metadata": {},
   "source": [
    "### Search 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "lyric-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #12 min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.7'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [200]\n",
    "# list_k = [2]\n",
    "# list_max_depth = [i for i in range(1,501, 50)]\n",
    "# list_n_estimators = [500]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-screen",
   "metadata": {},
   "source": [
    "### Search 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cleared-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 9 min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.8'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [200]\n",
    "# list_k = [2]\n",
    "# list_max_depth = [i for i in range(1,101, 10)]\n",
    "# list_n_estimators = [500]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-brunswick",
   "metadata": {},
   "source": [
    "### Search 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "invisible-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 51 min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.9'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [200]\n",
    "# list_k = [2]\n",
    "# list_max_depth = [i for i in range(10,101, 2)]\n",
    "# list_n_estimators = [500]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-vancouver",
   "metadata": {},
   "source": [
    "### Search 1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "greater-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 16 min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.10'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [200]\n",
    "# list_k = [2]\n",
    "# list_max_depth = [72]\n",
    "# list_n_estimators = [i for i in range(2,103,10)] + [i for i in range(100,1001,100)]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-serbia",
   "metadata": {},
   "source": [
    "### Search 1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "intelligent-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 12 min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.11'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [200]\n",
    "# list_k = [2]\n",
    "# list_max_depth = [72]\n",
    "# list_n_estimators = [i for i in range(200,501,25)]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-radical",
   "metadata": {},
   "source": [
    "### Search 1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "competitive-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 1h\n",
    "\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.12'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [10,20,50,100,200,400]\n",
    "# list_k = [1,2,4,6,8,10,12,14,16,18,20]\n",
    "# list_max_depth = [72]\n",
    "# list_n_estimators = [500]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-kitchen",
   "metadata": {},
   "source": [
    "### Search 1.13\n",
    "Searching over smaller max_depth and n_estimator space due to limitations as we scale up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "marked-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 22 min\n",
    "\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch-2000/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '1.13'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [10,100,200,400]\n",
    "# list_k = [1,2,4]\n",
    "# list_max_depth = [i for i in range(5,30,5)]\n",
    "# list_n_estimators = [i for i in range(20,50,5)]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-chess",
   "metadata": {},
   "source": [
    "### Search 1.14\n",
    "Switching to species-level recall and rechecking highest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bronze-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# grid_search_file  = 'data/gridsearch-2000/rf-multi.{}.csv'.format(datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S') )\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','max_depth', 'n_estimators', 'score','score type']\n",
    "# experiment = '1.14'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [400]\n",
    "# list_k = [1]\n",
    "# list_max_depth = [15]\n",
    "# list_n_estimators = [45]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-child",
   "metadata": {},
   "source": [
    "# Grid Search 2 - 10000 size dataset (198 examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-teacher",
   "metadata": {},
   "source": [
    "### Search 2.01\n",
    "Determine if method even works with new data.\n",
    "Result: takes a long time to complete even a single run with 500 estimators and 72 max depth. May need to reduce one or both - reconsider how grid search 1 performs with higher coverage but lower estimators / depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "stock-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 47 min\n",
    "\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-10000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-10000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-10000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-10000/rf-multi.{}.csv'.format(date_time )\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '2.01'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [10]\n",
    "# list_k = [1]\n",
    "# list_max_depth = [72]\n",
    "# list_n_estimators = [500]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-packet",
   "metadata": {},
   "source": [
    "### Search 2.02\n",
    "10x less estimators. Checking to see how time changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "latin-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 5 min\n",
    "\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-10000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-10000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-10000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-10000/rf-multi.{}.csv'.format(date_time )\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '2.02'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [10]\n",
    "# list_k = [1]\n",
    "# list_max_depth = [72]\n",
    "# list_n_estimators = [50]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-mixture",
   "metadata": {},
   "source": [
    "### Search 2.03\n",
    "10x less depth. Checking to see how time changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "outer-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 2 min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-10000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-10000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-10000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-10000/rf-multi.{}.csv'.format(date_time )\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '2.03'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [10]\n",
    "# list_k = [1]\n",
    "# list_max_depth = [7]\n",
    "# list_n_estimators = [500]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-surface",
   "metadata": {},
   "source": [
    "### Search 2.04\n",
    "Stopped early because we don't need to try k values higher than 4 because the accuracy is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "several-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-10000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-10000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-10000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-10000/rf-multi.{}.csv'.format(date_time )\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '2.04'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [20,50,100,200,400]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_max_depth = [72]\n",
    "# list_n_estimators = [50]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-enzyme",
   "metadata": {},
   "source": [
    "### Search 2.05\n",
    "Stopped after first run at 400x sample coverage. Took at least 10 hours for that run alone, maybe longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "confidential-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-10000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-10000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-10000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-10000/rf-multi.{}.csv'.format(date_time )\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '2.05'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [200,400]\n",
    "# list_coverage = [10,50,100,200,400]\n",
    "# list_k = [1,2,4]\n",
    "# list_max_depth = [72]\n",
    "# list_n_estimators = [50]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-banana",
   "metadata": {},
   "source": [
    "### Search 2.06\n",
    "Testing with small max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "statutory-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 10 h 15 min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-10000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-10000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-10000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-10000/rf-multi.{}.csv'.format(date_time )\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','max_depth', 'n_estimators', 'score']\n",
    "# experiment = '2.06'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [10,100,200,400]\n",
    "# list_k = [1,2,4]\n",
    "# list_max_depth = [15]\n",
    "# list_n_estimators = [45]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-least",
   "metadata": {},
   "source": [
    "# Real Runs - 10000 size dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-graphics",
   "metadata": {},
   "source": [
    "### Run 3.01\n",
    "Testing with small max_depth and n_estimators to get initial round of data for diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "irish-version",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 11 h\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-10000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-10000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-10000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = None\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/runs-10000/rf-multi.{}.csv'.format(date_time )\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','max_depth', 'n_estimators', 'score','score type']\n",
    "# experiment = '3.01'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [0.1,1,10,100,400]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_max_depth = [15]\n",
    "# list_n_estimators = [50]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_rf(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_max_depth,\n",
    "#                           list_n_estimators, \n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-sender",
   "metadata": {},
   "source": [
    "### Run 3.02\n",
    "Run for coverage=200 using previous configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-christmas",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2467948, 400)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# parameters\n",
    "seq_file = 'data/train_small-db_toy-10000.fasta'\n",
    "taxid_file = 'data/train_small-db_toy-10000.taxid'\n",
    "output_dir = 'data/sampling/sampling-toy-10000'\n",
    "pattern = 'fragments*.npy'\n",
    "seed = None\n",
    "date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "grid_search_file  = 'data/runs-10000/rf-multi.{}.csv'.format(date_time )\n",
    "fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','max_depth', 'n_estimators', 'score','score type']\n",
    "experiment = '3.02'\n",
    "score_type = 'species_recall'\n",
    "\n",
    "# combinations to try\n",
    "list_sample_length = [100,200,400]\n",
    "list_coverage = [200]\n",
    "list_k = [1,2,4,6,8,10,12]\n",
    "list_max_depth = [15]\n",
    "list_n_estimators = [50]\n",
    "\n",
    "\n",
    "grid_search_multiclass_rf(seq_file, \n",
    "                          taxid_file, \n",
    "                          output_dir, \n",
    "                          pattern, \n",
    "                          list_sample_length, \n",
    "                          list_coverage, \n",
    "                          list_k, \n",
    "                          list_max_depth,\n",
    "                          list_n_estimators, \n",
    "                          seed,\n",
    "                          grid_search_file,\n",
    "                          fields,\n",
    "                          experiment,\n",
    "                          score_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line(sample_length, coverage, df):\n",
    "    data = df[(df['sample_length'] == sample_length) & (df['coverage']==coverage)].drop(['sample_length', 'coverage'],axis=1)\n",
    "    return data['k'].tolist(), data['score'].tolist()\n",
    "\n",
    "\n",
    "def plot_graphs(filename):\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.drop(['experiment','category','classifier','training shape', 'score type', 'max_depth','n_estimators'],axis=1)\n",
    "   \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n",
    "#     fig.tight_layout()\n",
    "\n",
    "    # graph 1\n",
    "    L=100\n",
    "    line_L100_C0_1_k, line_L100_C0_1_score = get_line(L, 0.1, df)\n",
    "    line_L100_C1_k, line_L100_C1_score = get_line(L, 1, df)\n",
    "    line_L100_C10_k, line_L100_C10_score = get_line(L, 10, df)\n",
    "    line_L100_C100_k, line_L100_C100_score = get_line(L, 100, df)\n",
    "    line_L100_C400_k, line_L100_C400_score = get_line(L, 400, df)\n",
    "    \n",
    "    ax1.plot(line_L100_C0_1_k, line_L100_C0_1_score, linestyle='-', label='cov=0.1',color='k')\n",
    "    ax1.plot(line_L100_C1_k, line_L100_C1_score, linestyle='--', label='cov=1',color='k')\n",
    "    ax1.plot(line_L100_C10_k, line_L100_C10_score, linestyle='-', label='cov=10',color='gray')\n",
    "    ax1.plot(line_L100_C100_k, line_L100_C100_score, linestyle=':', label='cov=100',color='gray')\n",
    "    ax1.plot(line_L100_C400_k, line_L100_C400_score, linestyle='-.', label='cov=400',color='k')\n",
    "\n",
    "    ax1.set_xticks([0, 1, 2,4,6,8,10,12])\n",
    "    ax1.legend()\n",
    "    ax1.set_title('L=100')\n",
    "    ax1.set_ylabel('average species-level recall')\n",
    "    ax1.set_xlabel('k-mer size')\n",
    "    ax1.grid(color='lightgray', linestyle=':', linewidth=1)\n",
    "    \n",
    "    # graph 2\n",
    "    L=200\n",
    "    line_L100_C0_1_k, line_L100_C0_1_score = get_line(L, 0.1, df)\n",
    "    line_L100_C1_k, line_L100_C1_score = get_line(L, 1, df)\n",
    "    line_L100_C10_k, line_L100_C10_score = get_line(L, 10, df)\n",
    "    line_L100_C100_k, line_L100_C100_score = get_line(L, 100, df)\n",
    "    line_L100_C400_k, line_L100_C400_score = get_line(L, 400, df)\n",
    "    \n",
    "    \n",
    "    ax2.plot(line_L100_C0_1_k, line_L100_C0_1_score, linestyle='-', label='cov=0.1',color='k')\n",
    "    ax2.plot(line_L100_C1_k, line_L100_C1_score, linestyle='--', label='cov=1',color='k')\n",
    "    ax2.plot(line_L100_C10_k, line_L100_C10_score, linestyle='-', label='cov=10',color='gray')\n",
    "    ax2.plot(line_L100_C100_k, line_L100_C100_score, linestyle=':', label='cov=100',color='gray')\n",
    "    ax2.plot(line_L100_C400_k, line_L100_C400_score, linestyle='-.', label='cov=400',color='k')\n",
    "\n",
    "    ax2.set_xticks([0, 1, 2,4,6,8,10,12])\n",
    "    ax2.legend()\n",
    "    ax2.set_title('L=200')\n",
    "    ax2.set_ylabel('average species-level recall')\n",
    "    ax2.set_xlabel('k-mer size')\n",
    "    ax2.grid(color='lightgray', linestyle=':', linewidth=1)\n",
    "    \n",
    "    # graph 3\n",
    "    L=400\n",
    "    line_L100_C0_1_k, line_L100_C0_1_score = get_line(L, 0.1, df)\n",
    "    line_L100_C1_k, line_L100_C1_score = get_line(L, 1, df)\n",
    "    line_L100_C10_k, line_L100_C10_score = get_line(L, 10, df)\n",
    "    line_L100_C100_k, line_L100_C100_score = get_line(L, 100, df)\n",
    "    line_L100_C400_k, line_L100_C400_score = get_line(L, 400, df)\n",
    "\n",
    "    \n",
    "    ax3.plot(line_L100_C0_1_k, line_L100_C0_1_score, linestyle='-', label='cov=0.1',color='k')\n",
    "    ax3.plot(line_L100_C1_k, line_L100_C1_score, linestyle='--', label='cov=1',color='k')\n",
    "    ax3.plot(line_L100_C10_k, line_L100_C10_score, linestyle='-', label='cov=10',color='gray')\n",
    "    ax3.plot(line_L100_C100_k, line_L100_C100_score, linestyle=':', label='cov=100',color='gray')\n",
    "    ax3.plot(line_L100_C400_k, line_L100_C400_score, linestyle='-.', label='cov=400',color='k')\n",
    "\n",
    "    ax3.set_xticks([0, 1, 2,4,6,8,10,12])\n",
    "    ax3.legend()\n",
    "    ax3.set_title('L=400')\n",
    "    ax3.set_ylabel('average species-level recall')\n",
    "    ax3.set_xlabel('k-mer size')\n",
    "    ax3.grid(color='lightgray', linestyle=':', linewidth=1)\n",
    "    \n",
    "    plt.suptitle(\"Random Forest Classifier (max_depth=15, n_estimators=50)\", fontsize=16)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "three-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='data/runs-10000/rf-multi.2021.04.06.21.33.27.csv'\n",
    "plot_graphs(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
