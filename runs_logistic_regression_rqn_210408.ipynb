{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cosmetic-australia",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "retired-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import csv\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from packages.metagenomics import sampling2, encoding2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from packages.LogisticRegression.MulticlassLogisticRegression import MulticlassLogisticRegression,MulticlassLogisticRegression2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-essex",
   "metadata": {},
   "source": [
    "### Ideas for improvements\n",
    "- try converting back to sparse matrix after adding augmented column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rapid-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_results_to_file(filename, fields=None, rows=None):\n",
    "    \n",
    "    with open(filename, 'a') as f:\n",
    "\n",
    "        write = csv.writer(f)\n",
    "\n",
    "        if fields:\n",
    "            write.writerow(fields)\n",
    "\n",
    "        if rows:\n",
    "            write.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "executed-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_mlr_classification_recall(X_train, X_test, y_train, y_test, eta, epsilon):\n",
    "#     \"\"\"\n",
    "#     Score is species level recall.\n",
    "#     \"\"\"\n",
    "#     mlr = MulticlassLogisticRegression2(eta=eta, epsilon=epsilon)\n",
    "#     mlr.fit(X_train,y_train)\n",
    "#     y_pred = mlr.predict(X_test)\n",
    "#     score = recall_score(y_test, y_pred, average='weighted')\n",
    "#     return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arabic-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fragments(seq_file, taxid_file, output_dir, sample_length, coverage, seed):\n",
    "    # delete output directory if it previously exists\n",
    "    try:\n",
    "        shutil.rmtree(output_dir)\n",
    "    except FileNotFoundError:\n",
    "        print('Existing directory was not found. Process will generate a directory.')\n",
    "\n",
    "    # build fragments\n",
    "    sampling2.generate_fragment_data(seq_file, taxid_file, output_dir, sample_length, coverage, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prerequisite-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fragments(output_dir, pattern, k, seed):\n",
    "    \"\"\"\n",
    "    Converts sparse matrix to array before splitting.\n",
    "    \"\"\"\n",
    "    \n",
    "    # encode data\n",
    "    fragments = sampling2.read_fragments(output_dir, pattern)\n",
    "    X_enc, y = encoding2.encode_fragment_dataset(fragments,k)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "    \n",
    "    # calculate number of classes\n",
    "    n_classes = len(np.unique(y_enc))\n",
    "#     print('n_classes:',n_classes)\n",
    "    n_classes_train = 0\n",
    "    n_classes_test = 0\n",
    "    while n_classes_train < n_classes or n_classes_test < n_classes:\n",
    "\n",
    "        # split data into test and training\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_enc.toarray(), y_enc, test_size=0.33)\n",
    "        n_classes_train = len(np.unique(y_train))\n",
    "        n_classes_test = len(np.unique(y_test))\n",
    "#         print('train:',len(y_train))\n",
    "#         print('test:', len(y_test))\n",
    "    \n",
    "    print(X_enc.shape)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "listed-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_number_combinations(list_sample_length,list_coverage,list_k,list_eta,list_epsilon):\n",
    "#     n = len(list_sample_length) * len(list_coverage) * len(list_k) *len(list_eta) * len(list_epsilon)\n",
    "#     return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "worse-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grid_search_multiclass_mlr(seq_file, \n",
    "#                               taxid_file, \n",
    "#                               output_dir, \n",
    "#                               pattern, \n",
    "#                               list_sample_length, \n",
    "#                               list_coverage, \n",
    "#                               list_k,\n",
    "#                               list_eta,\n",
    "#                               list_epsilon, \n",
    "#                               seed,\n",
    "#                               grid_search_file,\n",
    "#                               fields,\n",
    "#                               experiment,\n",
    "#                               score_type):\n",
    "    \n",
    "#     # set up grid search results file\n",
    "#     append_results_to_file(grid_search_file, fields)\n",
    "    \n",
    "#     # calculate number of combinations\n",
    "#     n_combinations = calc_number_combinations(list_sample_length,list_coverage,list_k,list_eta,list_epsilon)\n",
    "    \n",
    "#     # process combinations\n",
    "#     count = 0\n",
    "#     for sample_length in list_sample_length:\n",
    "#         for coverage in list_coverage:\n",
    "            \n",
    "#             # fragment combination\n",
    "#             build_fragments(seq_file, taxid_file, output_dir, sample_length, coverage, seed)\n",
    "#             for k in list_k:\n",
    "                \n",
    "#                 # kmer combination\n",
    "#                 X_train, X_test, y_train, y_test = encode_fragments(output_dir, pattern,k,seed)\n",
    "#                 for eta in list_eta:\n",
    "#                     for epsilon in list_epsilon:\n",
    "                        \n",
    "#                         # random forest combination\n",
    "#                         score = run_mlr_classification_recall(X_train, X_test, y_train,y_test, eta, epsilon)\n",
    "#                         count += 1\n",
    "                        \n",
    "#                         # output results to file\n",
    "#                         row = [experiment, 'multiclass', 'Logistic Regression', X_train.shape, sample_length, coverage, k, eta, epsilon, score, score_type]\n",
    "#                         append_results_to_file(grid_search_file, row)\n",
    "                        \n",
    "#                 print('Percent complete: {}'.format(count / n_combinations * 100)) # display progress\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-dietary",
   "metadata": {},
   "source": [
    "# Run Set 1 - MLR Toy\n",
    "2000 lengths dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-sphere",
   "metadata": {},
   "source": [
    "### Run 4.01\n",
    "Stopped early due to runs taking a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "solar-boulder",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000-mlr'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/runs-2000/mlr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','eta', 'epsilon', 'score','score type']\n",
    "# experiment = '4.01'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [0.2,1,10]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_eta = [0.01]\n",
    "# list_epsilon = [0.01]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_mlr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_eta,\n",
    "#                           list_epsilon,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-labor",
   "metadata": {},
   "source": [
    "### Run 4.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "anonymous-reward",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000-mlr'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/runs-2000/mlr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','eta', 'epsilon', 'score','score type']\n",
    "# experiment = '4.02'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [200]\n",
    "# list_coverage = [0.3,1,10]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_eta = [0.01]\n",
    "# list_epsilon = [0.01]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_mlr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_eta,\n",
    "#                           list_epsilon,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-preservation",
   "metadata": {},
   "source": [
    "### Run 4.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exposed-message",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000-mlr'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/runs-2000/mlr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','eta', 'epsilon', 'score','score type']\n",
    "# experiment = '4.03'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [400]\n",
    "# list_coverage = [0.5,1,10]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_eta = [0.01]\n",
    "# list_epsilon = [0.01]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_mlr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_eta,\n",
    "#                           list_epsilon,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-flexibility",
   "metadata": {},
   "source": [
    "### Run 4.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "environmental-header",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000-mlr'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/runs-2000/mlr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','eta', 'epsilon', 'score','score type']\n",
    "# experiment = '4.04'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [100]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_eta = [0.01]\n",
    "# list_epsilon = [0.01]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_mlr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_eta,\n",
    "#                           list_epsilon,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-honor",
   "metadata": {},
   "source": [
    "### Run 4.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "major-alfred",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "##40 min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000-mlr'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/runs-2000/mlr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','eta', 'epsilon', 'score','score type']\n",
    "# experiment = '4.05'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [200]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_eta = [0.01]\n",
    "# list_epsilon = [0.01]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_mlr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_eta,\n",
    "#                           list_epsilon,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-assignment",
   "metadata": {},
   "source": [
    "# Run Set 2 - sklearn with l1 penalty\n",
    "Compare with sklearn implementation of MLR to see if performance is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "numeric-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_number_combinations2(list_sample_length,list_coverage,list_k,list_multiclass,list_classweight):\n",
    "#     n = len(list_sample_length) * len(list_coverage) * len(list_k) *len(list_multiclass) * len(list_classweight)\n",
    "#     return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "expanded-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fragments2(output_dir, pattern, k, seed):\n",
    "    \"\"\"\n",
    "    Does not convert sparse matrix to numpy matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    # encode data\n",
    "    fragments = sampling2.read_fragments(output_dir, pattern)\n",
    "    X_enc, y = encoding2.encode_fragment_dataset(fragments,k)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "    \n",
    "    # calculate number of classes\n",
    "    n_classes = len(np.unique(y_enc))\n",
    "#     print('n_classes:',n_classes)\n",
    "    n_classes_train = 0\n",
    "    n_classes_test = 0\n",
    "    while n_classes_train < n_classes or n_classes_test < n_classes:\n",
    "\n",
    "        # split data into test and training\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_enc, y_enc, test_size=0.33)\n",
    "        n_classes_train = len(np.unique(y_train))\n",
    "        n_classes_test = len(np.unique(y_test))\n",
    "#         print('train:',y_train)\n",
    "#         print('test:', y_test)\n",
    "    \n",
    "    print(X_enc.shape)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "manual-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_lr_classification_recall(X_train, X_test, y_train, y_test, multiclass, classweight, seed ):\n",
    "#     \"\"\"\n",
    "#     Score is species level recall. Uses sklearn version of logistic regression.\n",
    "#     \"\"\"\n",
    "#     lr = LogisticRegression(random_state=seed, multi_class=multiclass, class_weight=classweight )\n",
    "#     lr.fit(X_train,y_train)\n",
    "#     y_pred = lr.predict(X_test)\n",
    "#     score = recall_score(y_test, y_pred, average='weighted')\n",
    "#     return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "casual-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grid_search_multiclass_lr(seq_file, \n",
    "#                               taxid_file, \n",
    "#                               output_dir, \n",
    "#                               pattern, \n",
    "#                               list_sample_length, \n",
    "#                               list_coverage, \n",
    "#                               list_k,\n",
    "#                               list_multiclass,\n",
    "#                               list_classweight,\n",
    "#                               seed,\n",
    "#                               grid_search_file,\n",
    "#                               fields,\n",
    "#                               experiment,\n",
    "#                               score_type):\n",
    "    \n",
    "#     # set up grid search results file\n",
    "#     append_results_to_file(grid_search_file, fields)\n",
    "    \n",
    "#     # calculate number of combinations\n",
    "#     n_combinations = calc_number_combinations2(list_sample_length,list_coverage,list_k, list_multiclass, list_classweight)\n",
    "    \n",
    "#     # process combinations\n",
    "#     count = 0\n",
    "#     for sample_length in list_sample_length:\n",
    "#         for coverage in list_coverage:\n",
    "            \n",
    "#             # fragment combination\n",
    "#             build_fragments(seq_file, taxid_file, output_dir, sample_length, coverage, seed)\n",
    "#             for k in list_k:\n",
    "                \n",
    "#                 # kmer combination\n",
    "#                 X_train, X_test, y_train, y_test = encode_fragments2(output_dir, pattern,k,seed)\n",
    "                \n",
    "                \n",
    "#                 for multiclass in list_multiclass:\n",
    "#                     for classweight in list_classweight:\n",
    "\n",
    "                        \n",
    "#                         # random forest combination\n",
    "#                         score = run_lr_classification_recall(X_train, X_test, y_train, y_test, multiclass, classweight, seed)\n",
    "#                         count += 1\n",
    "\n",
    "#                         # output results to file\n",
    "#                         row = [experiment, 'multiclass', 'Logistic Regression (sklearn)', X_train.shape, sample_length, coverage, k, multiclass, classweight, score, score_type]\n",
    "#                         append_results_to_file(grid_search_file, row)\n",
    "\n",
    "#                 print('Percent complete: {}'.format(count / n_combinations * 100)) # display progress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-absorption",
   "metadata": {},
   "source": [
    "### Run 5.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "twenty-competition",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/runs-2000/lr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','multiclass', 'class_weight', 'score','score type']\n",
    "# experiment = '5.01'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [1,10,100,200,400]\n",
    "# list_k = [1]\n",
    "# list_multiclass = ['auto']\n",
    "# list_classweight= [None]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_lr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_multiclass,\n",
    "#                           list_classweight,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-playing",
   "metadata": {},
   "source": [
    "### Run 5.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "golden-triangle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/runs-2000/lr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','multiclass', 'class_weight', 'score','score type']\n",
    "# experiment = '5.02'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [1,10,100,200,400]\n",
    "# list_k = [2,4,6,8,10,12]\n",
    "# list_multiclass = ['auto']\n",
    "# list_classweight= [None]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_lr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_multiclass,\n",
    "#                           list_classweight,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-terminology",
   "metadata": {},
   "source": [
    "# Run Set 3 - MLR with L2 penalty\n",
    "- toy-2000 dataset\n",
    "- See how performance changes with L2 penalty\n",
    "- Changed breakpoint in gradient descent to 100 from 100,000 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "authentic-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_number_combinations(*args):\n",
    "    total = 1\n",
    "    for each in args:\n",
    "        total *= len(each)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "through-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_generator(list_sample_length,list_coverage,list_k):\n",
    "    \n",
    "    for L in list_sample_length:\n",
    "        for c in list_coverage:\n",
    "            for k in list_k:\n",
    "                yield L, c, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "turkish-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hyperparameter_generator(list_eta,list_epsilon, list_penalty, list_l2_lambda,list_max_iter):\n",
    "    \n",
    "#     for eta in list_eta:\n",
    "#         for e in list_epsilon:\n",
    "#             for penalty in list_penalty:\n",
    "#                 for l2 in list_l2_lambda:\n",
    "#                     for m in list_max_iter:\n",
    "#                         yield eta,e,penalty,l2,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "enclosed-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlr_classification_recall(X_train, X_test, y_train, y_test, eta, epsilon, penalty, l2_lambda, max_iter):\n",
    "    \"\"\"\n",
    "    Score is species level recall.\n",
    "    \"\"\"\n",
    "    mlr = MulticlassLogisticRegression2(eta=eta, \n",
    "                                        epsilon=epsilon, \n",
    "                                        penalty=penalty, \n",
    "                                        l2_lambda=l2_lambda, \n",
    "                                        max_iter=max_iter)\n",
    "    mlr.fit(X_train,y_train)\n",
    "    y_pred = mlr.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred, average='weighted')\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "streaming-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_multiclass_mlr(seq_file, \n",
    "                              taxid_file, \n",
    "                              output_dir, \n",
    "                              pattern, \n",
    "                              list_sample_length, \n",
    "                              list_coverage, \n",
    "                              list_k,\n",
    "                              list_eta,\n",
    "                              list_epsilon, \n",
    "                              list_penalty,\n",
    "                              list_l2_lambda,\n",
    "                              list_max_iter,\n",
    "                              seed,\n",
    "                              grid_search_file,\n",
    "                              fields,\n",
    "                              experiment,\n",
    "                              score_type):\n",
    "    \n",
    "    # set up grid search results file\n",
    "    append_results_to_file(grid_search_file, fields)\n",
    "    \n",
    "    # calculate number of combinations\n",
    "    n_combinations = calc_number_combinations(list_sample_length,\n",
    "                                              list_coverage,\n",
    "                                              list_k,\n",
    "                                              list_eta,\n",
    "                                              list_epsilon, \n",
    "                                              list_penalty,\n",
    "                                              list_l2_lambda, \n",
    "                                              list_max_iter)\n",
    "    \n",
    "    # process combinations\n",
    "    count = 0\n",
    "    sample_length_prev = -1\n",
    "    coverage_prev = -1\n",
    "    \n",
    "    # parameter combinations\n",
    "    for sample_length, coverage,k in parameter_generator(list_sample_length,list_coverage,list_k):\n",
    "        print(sample_length, coverage,k)\n",
    "        \n",
    "        if sample_length != sample_length_prev or coverage != coverage_prev:\n",
    "            \n",
    "            # fragment combination\n",
    "            build_fragments(seq_file, taxid_file, output_dir, sample_length, coverage, seed)\n",
    "            \n",
    "            # update previous values\n",
    "            sample_length_prev = sample_length\n",
    "            coverage_prev = coverage\n",
    "                \n",
    "        # kmer from fragments\n",
    "        X_train, X_test, y_train, y_test = encode_fragments(output_dir, pattern,k,seed)\n",
    "        \n",
    "        \n",
    "        # hyperparameter combinations\n",
    "        for eta, epsilon, penalty, l2_lambda, max_iter in hyperparameter_generator(list_eta,list_epsilon, list_penalty, list_l2_lambda,list_max_iter):\n",
    "            print(eta, epsilon, penalty, l2_lambda, max_iter)\n",
    "            \n",
    "            # train and score model\n",
    "            score = run_mlr_classification_recall(X_train, X_test, y_train, y_test, eta, epsilon, penalty, l2_lambda, max_iter)\n",
    "            count += 1\n",
    "\n",
    "            # output results to file\n",
    "            row = [experiment, 'multiclass', 'Logistic Regression', X_train.shape, sample_length, coverage, k, eta, epsilon, penalty, l2_lambda, max_iter, score, score_type]\n",
    "            append_results_to_file(grid_search_file, row)\n",
    "                        \n",
    "        print('Percent complete: {}'.format(count / n_combinations * 100)) # display progress\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-smell",
   "metadata": {},
   "source": [
    "### Run 6.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "academic-breakdown",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000-mlr'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/runs-2000/mlr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','eta', 'epsilon', 'l2_penalty','score','score type']\n",
    "# experiment = '6.01'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [1,10,100,200,400]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_eta = [0.01]\n",
    "# list_epsilon = [0.01]\n",
    "# list_l2_penalty = [1,10,100, 0.1]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_mlr_l2(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_eta,\n",
    "#                           list_epsilon,\n",
    "#                           list_l2_penalty,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-citizenship",
   "metadata": {},
   "source": [
    "### Run 6.02\n",
    "Testing out range for lambda. It appears that close to zero (0, 0.1) is best, with values decreasing more after 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "centered-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-2000/mlr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment',\n",
    "#           'category',\n",
    "#           'classifier',\n",
    "#           'training shape',\n",
    "#           'sample_length',\n",
    "#           'coverage',\n",
    "#           'k',\n",
    "#           'eta', \n",
    "#           'epsilon', \n",
    "#           'penalty',\n",
    "#           'l2_lambda',\n",
    "#           'max_iter',\n",
    "#           'score',\n",
    "#           'score type']\n",
    "\n",
    "# experiment = '6.02'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [200]\n",
    "# list_k = [4]\n",
    "# list_eta = [0.01]\n",
    "# list_epsilon = [0.01]\n",
    "# list_penalty = ['l2']\n",
    "# list_l2_lambda = [0,0.1,0.5,1,3,6,10]\n",
    "# list_max_iter = [100]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_mlr(seq_file, \n",
    "#                                 taxid_file, \n",
    "#                                 output_dir, \n",
    "#                                 pattern, \n",
    "#                                 list_sample_length, \n",
    "#                                 list_coverage, \n",
    "#                                 list_k, \n",
    "#                                 list_eta,\n",
    "#                                 list_epsilon,\n",
    "#                                 list_penalty,\n",
    "#                                 list_l2_lambda,\n",
    "#                                 list_max_iter,\n",
    "#                                 seed,\n",
    "#                                 grid_search_file,\n",
    "#                                 fields,\n",
    "#                                 experiment,\n",
    "#                                 score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-approval",
   "metadata": {},
   "source": [
    "### Run 6.03\n",
    "Finishing out data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "center-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# 5.5 h\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-2000/mlr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment',\n",
    "#           'category',\n",
    "#           'classifier',\n",
    "#           'training shape',\n",
    "#           'sample_length',\n",
    "#           'coverage',\n",
    "#           'k',\n",
    "#           'eta', \n",
    "#           'epsilon', \n",
    "#           'penalty',\n",
    "#           'l2_lambda',\n",
    "#           'max_iter',\n",
    "#           'score',\n",
    "#           'score type']\n",
    "\n",
    "# experiment = '6.03'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100]\n",
    "# list_coverage = [400]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_eta = [0.01]\n",
    "# list_epsilon = [0.01]\n",
    "# list_penalty = [None]\n",
    "# list_l2_lambda = [0]\n",
    "# list_max_iter = [100]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_mlr(seq_file, \n",
    "#                                 taxid_file, \n",
    "#                                 output_dir, \n",
    "#                                 pattern, \n",
    "#                                 list_sample_length, \n",
    "#                                 list_coverage, \n",
    "#                                 list_k, \n",
    "#                                 list_eta,\n",
    "#                                 list_epsilon,\n",
    "#                                 list_penalty,\n",
    "#                                 list_l2_lambda,\n",
    "#                                 list_max_iter,\n",
    "#                                 seed,\n",
    "#                                 grid_search_file,\n",
    "#                                 fields,\n",
    "#                                 experiment,\n",
    "#                                 score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-panama",
   "metadata": {},
   "source": [
    "### Run 6.04\n",
    "Finishing out data for plotting\n",
    "Try a larger learning rate to see if that speeds up processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ready-volume",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 4 h 32 min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-2000/mlr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment',\n",
    "#           'category',\n",
    "#           'classifier',\n",
    "#           'training shape',\n",
    "#           'sample_length',\n",
    "#           'coverage',\n",
    "#           'k',\n",
    "#           'eta', \n",
    "#           'epsilon', \n",
    "#           'penalty',\n",
    "#           'l2_lambda',\n",
    "#           'max_iter',\n",
    "#           'score',\n",
    "#           'score type']\n",
    "\n",
    "# experiment = '6.04'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [200,400]\n",
    "# list_coverage = [100,200,400]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_eta = [0.02]\n",
    "# list_epsilon = [0.01]\n",
    "# list_penalty = [None]\n",
    "# list_l2_lambda = [0]\n",
    "# list_max_iter = [100]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_mlr(seq_file, \n",
    "#                                 taxid_file, \n",
    "#                                 output_dir, \n",
    "#                                 pattern, \n",
    "#                                 list_sample_length, \n",
    "#                                 list_coverage, \n",
    "#                                 list_k, \n",
    "#                                 list_eta,\n",
    "#                                 list_epsilon,\n",
    "#                                 list_penalty,\n",
    "#                                 list_l2_lambda,\n",
    "#                                 list_max_iter,\n",
    "#                                 seed,\n",
    "#                                 grid_search_file,\n",
    "#                                 fields,\n",
    "#                                 experiment,\n",
    "#                                 score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-huntington",
   "metadata": {},
   "source": [
    "# Run Set 4 - sklearn with l1 penalty\n",
    "To compare against L2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "removable-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_generator_lr(list_penalty,list_multiclass,list_classweight):\n",
    "    \n",
    "    for penalty in list_penalty:\n",
    "        for multiclass in list_multiclass:\n",
    "            for classweight in list_classweight:\n",
    "                yield penalty,multiclass,classweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "greater-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lr_classification_recall(X_train, X_test, y_train, y_test, penalty,multiclass,classweight, seed):\n",
    "    \"\"\"\n",
    "    Score is species level recall.\n",
    "    Sets solver to 'saga' for l1 penalty. Uses default solver for l2 penalty. solver='saga'\n",
    "    \"\"\"\n",
    "    lr = LogisticRegression(penalty=penalty, multi_class=multiclass, class_weight=classweight,random_state=seed )\n",
    "    lr.fit(X_train,y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    score = recall_score(y_test, y_pred, average='weighted')\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "australian-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_multiclass_lr(seq_file, \n",
    "                          taxid_file, \n",
    "                          output_dir, \n",
    "                          pattern, \n",
    "                          list_sample_length, \n",
    "                          list_coverage, \n",
    "                          list_k, \n",
    "                          list_penalty,\n",
    "                          list_multiclass,\n",
    "                          list_classweight,\n",
    "                          seed,\n",
    "                          grid_search_file,\n",
    "                          fields,\n",
    "                          experiment,\n",
    "                          score_type):\n",
    "    \n",
    "    # set up grid search results file\n",
    "    append_results_to_file(grid_search_file, fields)\n",
    "    \n",
    "    # calculate number of combinations\n",
    "    n_combinations = calc_number_combinations(list_sample_length,\n",
    "                                              list_coverage,\n",
    "                                              list_k,\n",
    "                                              list_penalty,\n",
    "                                              list_multiclass,\n",
    "                                              list_classweight)\n",
    "    \n",
    "    # process combinations\n",
    "    count = 0\n",
    "    sample_length_prev = -1\n",
    "    coverage_prev = -1\n",
    "    \n",
    "    # parameter combinations\n",
    "    for sample_length, coverage,k in parameter_generator(list_sample_length,list_coverage,list_k):\n",
    "        print(sample_length, coverage,k)\n",
    "        \n",
    "        if sample_length != sample_length_prev or coverage != coverage_prev:\n",
    "            \n",
    "            # fragment combination\n",
    "            build_fragments(seq_file, taxid_file, output_dir, sample_length, coverage, seed)\n",
    "            \n",
    "            # update previous values\n",
    "            sample_length_prev = sample_length\n",
    "            coverage_prev = coverage\n",
    "                \n",
    "        # kmer from fragments\n",
    "        X_train, X_test, y_train, y_test = encode_fragments2(output_dir, pattern,k,seed)\n",
    "        \n",
    "        \n",
    "        # hyperparameter combinations\n",
    "        for penalty,multiclass,classweight in hyperparameter_generator_lr(list_penalty,list_multiclass,list_classweight):\n",
    "            print(penalty,multiclass,classweight)\n",
    "            \n",
    "            # train and score model\n",
    "            score = run_lr_classification_recall(X_train, X_test, y_train, y_test, penalty,multiclass,classweight, seed)\n",
    "            count += 1\n",
    "\n",
    "            # output results to file\n",
    "            row = [experiment, 'multiclass', 'Logistic Regression (sklearn)', X_train.shape, sample_length, coverage, k, penalty, multiclass, classweight, score, score_type]\n",
    "            append_results_to_file(grid_search_file, row)\n",
    "                        \n",
    "        print('Percent complete: {}'.format(count / n_combinations * 100)) # display progress\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-square",
   "metadata": {},
   "source": [
    "### Run 7.01 - l1 penalty with saga solver\n",
    "Can't use default solver with l1 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "conditional-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 40 min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-2000/lr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','penalty','multi_class', 'class_weight', 'score','score type']\n",
    "# experiment = '7.01'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [1,10,100,200,400]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_penalty=['l1']\n",
    "# list_multiclass = ['auto']\n",
    "# list_classweight= [None]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_lr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_penalty,\n",
    "#                           list_multiclass,\n",
    "#                           list_classweight,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-literacy",
   "metadata": {},
   "source": [
    "### Run 7.02 - Balanced class weights\n",
    "Set solver back to default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ranking-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# 3 min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-2000/lr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','penalty','multi_class', 'class_weight', 'score','score type']\n",
    "# experiment = '7.02'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [1,10,100,200,400]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_penalty=['l2']\n",
    "# list_multiclass = ['auto']\n",
    "# list_classweight= ['balanced']\n",
    "\n",
    "\n",
    "# grid_search_multiclass_lr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_penalty,\n",
    "#                           list_multiclass,\n",
    "#                           list_classweight,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-klein",
   "metadata": {},
   "source": [
    "### Run 7.03 - No penalty, no class weights\n",
    "Changed solver back to default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "verified-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 5 min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-2000/lr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','penalty','multi_class', 'class_weight', 'score','score type']\n",
    "# experiment = '7.03'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [1,10,100,200,400]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_penalty=['none']\n",
    "# list_multiclass = ['auto']\n",
    "# list_classweight= [None]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_lr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_penalty,\n",
    "#                           list_multiclass,\n",
    "#                           list_classweight,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-locking",
   "metadata": {},
   "source": [
    "### Run 7.04 - L2 penalty, ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "yellow-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# 3min\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-2000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-2000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-2000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-2000/lr-multi.{}.csv'.format(date_time)\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','penalty','multi_class', 'class_weight', 'score','score type']\n",
    "# experiment = '7.04'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [1,10,100,200,400]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_penalty=['l2']\n",
    "# list_multiclass = ['ovr']\n",
    "# list_classweight= [None]\n",
    "\n",
    "\n",
    "# grid_search_multiclass_lr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_penalty,\n",
    "#                           list_multiclass,\n",
    "#                           list_classweight,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-gentleman",
   "metadata": {},
   "source": [
    "# Run Set 9 - sklearn with l2 penalty and class weights on 7400 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-wellington",
   "metadata": {},
   "source": [
    "### Run 9.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "buried-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 2.5 hours\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-7400.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-7400.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-7400'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-7400/results-lrpackage-l2-balanced.csv'\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','penalty','multi_class', 'class_weight', 'score','score type']\n",
    "# experiment = '9.01'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [1,10,100,200,400]\n",
    "# list_k = [1,2,4,6] # ,8,10,12\n",
    "# list_penalty=['l2']\n",
    "# list_multiclass = ['auto']\n",
    "# list_classweight= ['balanced']\n",
    "\n",
    "\n",
    "# grid_search_multiclass_lr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_penalty,\n",
    "#                           list_multiclass,\n",
    "#                           list_classweight,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-cocktail",
   "metadata": {},
   "source": [
    "### Run 9.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "choice-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-7400.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-7400.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-7400'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-7400/results-lrpackage-l2-balanced.csv'\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','penalty','multi_class', 'class_weight', 'score','score type']\n",
    "# experiment = '9.02'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [1,10,100,200,400]\n",
    "# list_k = [8,10,12]\n",
    "# list_penalty=['l2']\n",
    "# list_multiclass = ['auto']\n",
    "# list_classweight= ['balanced']\n",
    "\n",
    "\n",
    "# grid_search_multiclass_lr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_penalty,\n",
    "#                           list_multiclass,\n",
    "#                           list_classweight,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-tourism",
   "metadata": {},
   "source": [
    "# Run Set 10 - sklearn with l2 penalty and class weights on 5000 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-perfume",
   "metadata": {},
   "source": [
    "### Run 10.01\n",
    "Stopped early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "phantom-antenna",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # parameters\n",
    "# seq_file = 'data/train_small-db_toy-5000.fasta'\n",
    "# taxid_file = 'data/train_small-db_toy-5000.taxid'\n",
    "# output_dir = 'data/sampling/sampling-toy-5000'\n",
    "# pattern = 'fragments*.npy'\n",
    "# seed = 42\n",
    "# date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "# grid_search_file  = 'data/gridsearch-5000/results-lrpackage-l2-balanced.csv'\n",
    "# fields = ['experiment','category','classifier','training shape','sample_length','coverage','k','penalty','multi_class', 'class_weight', 'score','score type']\n",
    "# experiment = '10.01'\n",
    "# score_type = 'species_recall'\n",
    "\n",
    "# # combinations to try\n",
    "# list_sample_length = [100,200,400]\n",
    "# list_coverage = [1,10,100,200,400]\n",
    "# list_k = [1,2,4,6,8,10,12]\n",
    "# list_penalty=['l2']\n",
    "# list_multiclass = ['auto']\n",
    "# list_classweight= ['balanced']\n",
    "\n",
    "\n",
    "# grid_search_multiclass_lr(seq_file, \n",
    "#                           taxid_file, \n",
    "#                           output_dir, \n",
    "#                           pattern, \n",
    "#                           list_sample_length, \n",
    "#                           list_coverage, \n",
    "#                           list_k, \n",
    "#                           list_penalty,\n",
    "#                           list_multiclass,\n",
    "#                           list_classweight,\n",
    "#                           seed,\n",
    "#                           grid_search_file,\n",
    "#                           fields,\n",
    "#                           experiment,\n",
    "#                           score_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-salmon",
   "metadata": {},
   "source": [
    "# Run Set 12 - MLR with no penalty\n",
    "- toy-5000 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-emission",
   "metadata": {},
   "source": [
    "### Run 12.01\n",
    "Increased learning rate again because convergence was not occurring, and process is very slow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-clause",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 1\n",
      "(209680, 400)\n",
      "0.1 0.01 None 0 100\n",
      "n_classifiers 22\n",
      "training classifier 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanqnelson/GitHub/C-A-L-C-I-F-E-R/CMU-02620-Metagenomics/packages/LogisticRegression/gradient_descent.py:303: RuntimeWarning: overflow encountered in exp\n",
      "  inner = ones + np.exp(Xw)\n",
      "/Users/ryanqnelson/GitHub/C-A-L-C-I-F-E-R/CMU-02620-Metagenomics/packages/LogisticRegression/gradient_descent.py:254: RuntimeWarning: overflow encountered in exp\n",
      "  top = np.exp(Xw)\n",
      "/Users/ryanqnelson/GitHub/C-A-L-C-I-F-E-R/CMU-02620-Metagenomics/packages/LogisticRegression/gradient_descent.py:257: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return top / bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training classifier 1\n",
      "training classifier 2\n",
      "training classifier 3\n",
      "training classifier 4\n",
      "training classifier 5\n",
      "training classifier 6\n",
      "training classifier 7\n",
      "training classifier 8\n",
      "training classifier 9\n",
      "training classifier 10\n",
      "training classifier 11\n",
      "training classifier 12\n",
      "training classifier 13\n",
      "training classifier 14\n",
      "training classifier 15\n",
      "training classifier 16\n",
      "training classifier 17\n",
      "training classifier 18\n",
      "training classifier 19\n",
      "training classifier 20\n",
      "training classifier 21\n",
      "Percent complete: 8.333333333333332\n",
      "100 100 2\n",
      "(209680, 800)\n",
      "0.1 0.01 None 0 100\n",
      "n_classifiers 22\n",
      "training classifier 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanqnelson/GitHub/C-A-L-C-I-F-E-R/CMU-02620-Metagenomics/packages/LogisticRegression/gradient_descent.py:303: RuntimeWarning: overflow encountered in exp\n",
      "  inner = ones + np.exp(Xw)\n",
      "/Users/ryanqnelson/GitHub/C-A-L-C-I-F-E-R/CMU-02620-Metagenomics/packages/LogisticRegression/gradient_descent.py:254: RuntimeWarning: overflow encountered in exp\n",
      "  top = np.exp(Xw)\n",
      "/Users/ryanqnelson/GitHub/C-A-L-C-I-F-E-R/CMU-02620-Metagenomics/packages/LogisticRegression/gradient_descent.py:257: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return top / bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training classifier 1\n",
      "training classifier 2\n",
      "training classifier 3\n",
      "training classifier 4\n",
      "training classifier 5\n",
      "training classifier 6\n",
      "training classifier 7\n",
      "training classifier 8\n",
      "training classifier 9\n",
      "training classifier 10\n",
      "training classifier 11\n",
      "training classifier 12\n",
      "training classifier 13\n",
      "training classifier 14\n",
      "training classifier 15\n",
      "training classifier 16\n",
      "training classifier 17\n",
      "training classifier 18\n",
      "training classifier 19\n",
      "training classifier 20\n",
      "training classifier 21\n",
      "Percent complete: 16.666666666666664\n",
      "100 100 4\n",
      "(209680, 6400)\n",
      "0.1 0.01 None 0 100\n",
      "n_classifiers 22\n",
      "training classifier 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanqnelson/GitHub/C-A-L-C-I-F-E-R/CMU-02620-Metagenomics/packages/LogisticRegression/gradient_descent.py:303: RuntimeWarning: overflow encountered in exp\n",
      "  inner = ones + np.exp(Xw)\n",
      "/Users/ryanqnelson/GitHub/C-A-L-C-I-F-E-R/CMU-02620-Metagenomics/packages/LogisticRegression/gradient_descent.py:254: RuntimeWarning: overflow encountered in exp\n",
      "  top = np.exp(Xw)\n",
      "/Users/ryanqnelson/GitHub/C-A-L-C-I-F-E-R/CMU-02620-Metagenomics/packages/LogisticRegression/gradient_descent.py:257: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return top / bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training classifier 1\n",
      "training classifier 2\n",
      "training classifier 3\n",
      "training classifier 4\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "training classifier 5\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "training classifier 6\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "training classifier 7\n",
      "training classifier 8\n",
      "training classifier 9\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "training classifier 10\n",
      "training classifier 11\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "training classifier 12\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "training classifier 13\n",
      "training classifier 14\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "training classifier 15\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "training classifier 16\n",
      "training classifier 17\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "training classifier 18\n",
      "training classifier 19\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "training classifier 20\n",
      "training classifier 21\n",
      "Percent complete: 25.0\n",
      "100 100 6\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# parameters\n",
    "seq_file = 'data/train_small-db_toy-5000.fasta'\n",
    "taxid_file = 'data/train_small-db_toy-5000.taxid'\n",
    "output_dir = 'data/sampling/sampling-toy-5000'\n",
    "pattern = 'fragments*.npy'\n",
    "seed = 42\n",
    "date_time = datetime.datetime.now().strftime('%Y.%m.%d.%H.%M.%S')\n",
    "grid_search_file  = 'data/gridsearch-5000/results-5000-mlr.{}.csv'.format(date_time)\n",
    "fields = ['experiment',\n",
    "          'category',\n",
    "          'classifier',\n",
    "          'training shape',\n",
    "          'sample_length',\n",
    "          'coverage',\n",
    "          'k',\n",
    "          'eta', \n",
    "          'epsilon', \n",
    "          'penalty',\n",
    "          'l2_lambda',\n",
    "          'max_iter',\n",
    "          'score',\n",
    "          'score type']\n",
    "\n",
    "experiment = '12.02'\n",
    "score_type = 'species_recall'\n",
    "\n",
    "# combinations to try\n",
    "list_sample_length = [100]#,200,400\n",
    "list_coverage = [100,200,400] # 10,\n",
    "list_k = [1,2,4,6] # ,8,10,12\n",
    "list_eta = [0.1]\n",
    "list_epsilon = [0.01]\n",
    "list_penalty = [None]\n",
    "list_l2_lambda = [0]\n",
    "list_max_iter = [100]\n",
    "\n",
    "\n",
    "grid_search_multiclass_mlr(seq_file, \n",
    "                                taxid_file, \n",
    "                                output_dir, \n",
    "                                pattern, \n",
    "                                list_sample_length, \n",
    "                                list_coverage, \n",
    "                                list_k, \n",
    "                                list_eta,\n",
    "                                list_epsilon,\n",
    "                                list_penalty,\n",
    "                                list_l2_lambda,\n",
    "                                list_max_iter,\n",
    "                                seed,\n",
    "                                grid_search_file,\n",
    "                                fields,\n",
    "                                experiment,\n",
    "                                score_type)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
